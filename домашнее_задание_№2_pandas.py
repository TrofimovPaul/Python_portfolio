# -*- coding: utf-8 -*-
"""Домашнее задание №2. Pandas

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vznzCcXWt88sIdBWZ7wFZp2OJssvSyaD
"""

"""Задание 1
Скачайте с сайта grouplens.org...movielens/ датасет любого размера. Определите, какому фильму было выставлено больше всего оценок 5.0."""
import pandas as pd
df = pd.read_csv('ratings.csv')
df.head()

#df.info()
#df['rating'].value_counts().head()
top_movies = df.query('rating == 5.0')

top_dict = dict(top_movies['movieId'].value_counts(ascending = False).head(1))

df2 = pd.read_csv('movies.csv')
#df2.head()
for i in df2.movieId:
  if i in top_dict.keys():
    print('Best movie: '+list(df2.query(f'movieId == {i}').title)[0]+'\nPosition number: '+str(i))
  else:
    continue

"""Задание 2
По данным файла power.csv посчитайте суммарное потребление стран Прибалтики (Латвия, Литва и Эстония)
категорий 4, 12 и 21 за период с 2005 по 2010 года. Не учитывайте в расчетах отрицательные значения quantity."""
power = pd.read_csv('power.csv')
power.head()
filter_countries = power[(power['country'] =='Lithuania')|(power['country'] == 'Latvia')|(power['country'] == 'Estonia')]
filter_category = filter_countries[(filter_countries['category'] == 4)|(filter_countries['category'] == 12)|(filter_countries['category'] == 21)]
filter_year = filter_category[(filter_category['year']<=2010)&(filter_category['year']>=2005)]
#filter_year
filter_quantity = filter_year[(filter_year['quantity']>=0)]
print('Суммарное потребление стран Прибалтики: '+str(filter_quantity['quantity'].sum())+' ед.')
#power[power['country'].str.contains('est', case = False)]

"""Задание 3
Выберите страницу любого сайта с табличными данными. Импортируйте таблицы в pandas dataframe.
Примеры страниц (необязательно брать именно эти):"""
link1 = 'https://www.finanz.ru/valyuty/v-realnom-vremeni'
df3 = pd.read_html(link1, encoding='utf-8')[0]
#print(len(df3))
#df3.info()
print(df3)
df4 = pd.read_html(link1, encoding='utf-8')[1]
#print(len(df4))
#df4.info()
df5 = pd.read_html(link1, encoding='utf-8')[2]
#print(len(df5))
#df5.info()